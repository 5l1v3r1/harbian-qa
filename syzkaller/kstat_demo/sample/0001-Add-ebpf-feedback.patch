From c608c20b87233afd5366c3918ab6c55b485174aa Mon Sep 17 00:00:00 2001
From: Bins94 <kaipeng94@gmail.com>
Date: Wed, 20 Mar 2019 23:46:14 -0400
Subject: [PATCH 1/2] Add ebpf feedback

---
 executor/common.h       |   6 +-
 executor/common_linux.h |  40 ++++++++++---
 executor/executor.cc    | 121 +++++++++++++++++++++++++++++++++++-----
 pkg/ipc/ipc.go          |  23 ++++++--
 pkg/runtest/run.go      |   4 +-
 pkg/signal/signal.go    |   6 +-
 prog/analysis.go        |  10 ++--
 syz-fuzzer/proc.go      |   2 +-
 syz-manager/html.go     |   2 +-
 9 files changed, 173 insertions(+), 41 deletions(-)

diff --git a/executor/common.h b/executor/common.h
index 1d4d1883..93837465 100644
--- a/executor/common.h
+++ b/executor/common.h
@@ -481,7 +481,7 @@ again:
 #endif
 
 #if SYZ_EXECUTOR || SYZ_REPEAT
-static void execute_one(void);
+static void execute_one(int monpipe);
 #if SYZ_EXECUTOR_USES_FORK_SERVER
 #include <signal.h>
 #include <sys/types.h>
@@ -497,7 +497,7 @@ static void execute_one(void);
 static void reply_handshake();
 #endif
 
-static void loop(void)
+static void loop(int monpipe)
 {
 #if SYZ_HAVE_SETUP_LOOP
 	setup_loop();
@@ -558,7 +558,7 @@ static void loop(void)
 #if SYZ_EXECUTOR && SYZ_EXECUTOR_USES_SHMEM
 			close(kOutPipeFd);
 #endif
-			execute_one();
+			execute_one(monpipe);
 #if SYZ_HAVE_RESET_TEST
 			reset_test();
 #endif
diff --git a/executor/common_linux.h b/executor/common_linux.h
index 0e185553..8ba109a4 100644
--- a/executor/common_linux.h
+++ b/executor/common_linux.h
@@ -1896,7 +1896,7 @@ static void setup_common()
 #include <sys/time.h>
 #include <sys/wait.h>
 
-static void loop();
+static void loop(int monpipe);
 
 static void sandbox_common()
 {
@@ -1913,7 +1913,8 @@ static void sandbox_common()
 	close(netns);
 #endif
 
-	struct rlimit rlim;
+	/* Seems RLIMIT_STACK sometime break ebpf... unknow reason */
+	/*struct rlimit rlim;
 #if SYZ_EXECUTOR
 	rlim.rlim_cur = rlim.rlim_max = (200 << 20) +
 					(kMaxThreads * kCoverSize + kExtraCoverSize) * sizeof(void*);
@@ -1930,7 +1931,7 @@ static void sandbox_common()
 	rlim.rlim_cur = rlim.rlim_max = 0;
 	setrlimit(RLIMIT_CORE, &rlim);
 	rlim.rlim_cur = rlim.rlim_max = 256; // see kMaxFd
-	setrlimit(RLIMIT_NOFILE, &rlim);
+	setrlimit(RLIMIT_NOFILE, &rlim);*/
 
 	// CLONE_NEWNS/NEWCGROUP cause EINVAL on some systems,
 	// so we do them separately of clone in do_sandbox_namespace.
@@ -2016,7 +2017,32 @@ static int do_sandbox_none(void)
 #if SYZ_EXECUTOR || SYZ_ENABLE_NETDEV
 	initialize_netdevices();
 #endif
-	loop();
+	/* if the rawSignal is a single uint64,
+         * but not state convert edge, use pipe is ok
+         */
+	int monpipefd[2];
+	int ret = pipe(monpipefd);
+	if (ret < 0)
+	  fail("Pipe create failed\n");
+
+	int monpid = fork();
+	if (monpid == 0) {
+	  prctl(PR_SET_PDEATHSIG, SIGINT);
+	  dup2(monpipefd[1], STDOUT_FILENO);
+	  /* For reading monitor log print */
+	  close(monpipefd[0]);
+	  close(monpipefd[1]);
+	  debug("single ebpf start ...\n");
+	  execl("/root/pipe_monitor", "/root/pipe_monitor", "--debug", NULL);
+	  return 0;
+	}
+	/* ebpf loading is very slow, one time a vm restart */
+	sleep(6);
+
+	close(monpipefd[1]);
+        /*Only sandbox_none, feed zero to others sandbox_* */
+	loop(monpipefd[0]);
+
 	doexit(1);
 }
 #endif
@@ -2064,7 +2090,7 @@ static int do_sandbox_setuid(void)
 	// See task_dump_owner function in kernel.
 	prctl(PR_SET_DUMPABLE, 1, 0, 0, 0);
 
-	loop();
+	loop(0);
 	doexit(1);
 }
 #endif
@@ -2175,7 +2201,7 @@ static int namespace_sandbox_proc(void* arg)
 	if (syscall(SYS_capset, &cap_hdr, &cap_data))
 		fail("capset failed");
 
-	loop();
+	loop(0);
 	doexit(1);
 }
 
@@ -2332,7 +2358,7 @@ static int do_sandbox_android_untrusted_app(void)
 	initialize_netdevices();
 #endif
 
-	loop();
+	loop(0);
 	doexit(1);
 }
 #endif
diff --git a/executor/executor.cc b/executor/executor.cc
index f1f6ba29..d1dc2df6 100644
--- a/executor/executor.cc
+++ b/executor/executor.cc
@@ -17,6 +17,12 @@
 
 #include "defs.h"
 
+/* Separate state signal and coverage signal by high-4-bit
+ * So, syz-fuzzer can handle them differently
+ */
+#define STATE_SIG_MASK 0xf000000000000000
+#define COVERAGE_SIG_MASK 0xe0000000ffffffff
+
 #if defined(__GNUC__)
 #define SYSCALLAPI
 #define NORETURN __attribute__((noreturn))
@@ -95,9 +101,12 @@ const int kOutFd = 4;
 static uint32* output_data;
 static uint32* output_pos;
 static uint32* write_output(uint32 v);
+/* Extend signal to 64-bit, these functions' name end with *64  */
+static uint32* write_output64(uint64 v);
 static void write_completed(uint32 completed);
 static uint32 hash(uint32 a);
 static bool dedup(uint32 sig);
+static bool dedup2(uint32 sig);
 #endif
 
 enum sandbox_type {
@@ -203,6 +212,7 @@ struct thread_t {
 	uint32 reserrno;
 	bool fault_injected;
 	cover_t cov;
+        int monpipe;
 };
 
 static thread_t threads[kMaxThreads];
@@ -286,11 +296,11 @@ struct kcov_comparison_t {
 	bool operator<(const struct kcov_comparison_t& other) const;
 };
 
-static thread_t* schedule_call(int call_index, int call_num, bool colliding, uint64 copyout_index, uint64 num_args, uint64* args, uint64* pos);
+static thread_t* schedule_call(int call_index, int call_num, bool colliding, uint64 copyout_index, uint64 num_args, uint64* args, uint64* pos, int monpipe);
 static void handle_completion(thread_t* th);
 static void copyout_call_results(thread_t* th);
 static void write_call_output(thread_t* th, bool finished);
-static void write_extra_output();
+static void write_extra_output(int monpipe);
 static void execute_call(thread_t* th);
 static void thread_create(thread_t* th, int id);
 static void* worker_thread(void* arg);
@@ -547,8 +557,23 @@ void reply_execute(int status)
 }
 
 // execute_one executes program stored in input_data.
-void execute_one()
+void execute_one(int monpipe)
 {
+        /* Set the monpipe to NOBLOCK fd */
+        if(fcntl(monpipe, F_SETFL, O_NONBLOCK) < 0)
+	        fail("Failed to set O_NONBLOCK");
+	int n = 0;
+	char buf[0x11];
+	int ret = 17;
+	/* There may be some remnant data should be cleared */
+	while(ret > 0 || n < 100) {
+                ret = read(monpipe, buf, sizeof(buf));
+		if(ret > 0) {
+		        n = 0;
+		}
+		n++;
+	}
+	debug("Pipe is clear now!\n");
 	// Duplicate global collide variable on stack.
 	// Fuzzer once come up with ioctl(fd, FIONREAD, 0x920000),
 	// where 0x920000 was exactly collide address, so every iteration reset collide to 0.
@@ -673,8 +698,11 @@ retry:
 			args[i] = read_arg(&input_pos);
 		for (uint64 i = num_args; i < kMaxArgs; i++)
 			args[i] = 0;
+		/* Attach the monpipe to thread_t
+		 * so pipe can be used in write_coverage_signal
+		 */
 		thread_t* th = schedule_call(call_index++, call_num, colliding, copyout_index,
-					     num_args, args, input_pos);
+					     num_args, args, input_pos, monpipe);
 
 		if (colliding && (call_index % 2) == 0) {
 			// Don't wait for every other call.
@@ -728,7 +756,8 @@ retry:
 					write_call_output(th, false);
 				}
 			}
-			write_extra_output();
+			/* Actually, no extra state ... */
+			write_extra_output(monpipe);
 		}
 	}
 
@@ -739,17 +768,20 @@ retry:
 	}
 }
 
-thread_t* schedule_call(int call_index, int call_num, bool colliding, uint64 copyout_index, uint64 num_args, uint64* args, uint64* pos)
+thread_t* schedule_call(int call_index, int call_num, bool colliding, uint64 copyout_index, uint64 num_args, uint64* args, uint64* pos, int monpipe)
 {
 	// Find a spare thread to execute the call.
 	int i;
 	for (i = 0; i < kMaxThreads; i++) {
 		thread_t* th = &threads[i];
-		if (!th->created)
+		if (!th->created) {
 			thread_create(th, i);
+			th->monpipe = monpipe;
+		}
 		if (event_isset(&th->done)) {
 			if (th->executing)
 				handle_completion(th);
+			th->monpipe = monpipe;
 			break;
 		}
 	}
@@ -777,13 +809,44 @@ thread_t* schedule_call(int call_index, int call_num, bool colliding, uint64 cop
 
 #if SYZ_EXECUTOR_USES_SHMEM
 template <typename cover_data_t>
-void write_coverage_signal(cover_t* cov, uint32* signal_count_pos, uint32* cover_count_pos)
+void write_coverage_signal(cover_t* cov, uint32* signal_count_pos, uint32* cover_count_pos, int monpipe)
 {
 	// Write out feedback signals.
 	// Currently it is code edges computed as xor of two subsequent basic block PCs.
 	cover_data_t* cover_data = ((cover_data_t*)cov->data) + 1;
 	uint32 nsig = 0;
 	cover_data_t prev = 0;
+
+	/* Read both state signal and coverage signal is OK */
+	debug("Reading ...\n");
+	/* 64bit hex and a '\n' */
+	char buf[0x11];
+	int ret = 0x11, n= 0;
+	/* Be sure the signal of a syscall is really read */
+	while(ret > 0 || n < 1000) {
+	        memset(buf, 0, sizeof(buf));
+		ret = read(monpipe, buf, sizeof(buf));
+		uint32_t sig = 0;
+		uint64_t state = 0;
+		if(ret > 0) {
+		        state = strtol(buf, NULL, 16);
+			/* Only for deduplication */
+			sig = hash((state>>32)&0xfffffffff);
+			sig = (state&0xffffffff) ^ sig;
+			if (dedup2(sig))
+			        continue;
+			/* state signal start with 0xf
+			 * Write out real state for fuzzer's further handle
+			 */
+			write_output64(state|STATE_SIG_MASK);
+			debug("A state signal %016lx\n", state);
+			n = 0;
+			nsig++;
+		}
+		sig = 0;
+		n++;
+	}
+
 	for (uint32 i = 0; i < cov->size; i++) {
 		cover_data_t pc = cover_data[i];
 		if (!cover_check(pc)) {
@@ -794,7 +857,7 @@ void write_coverage_signal(cover_t* cov, uint32* signal_count_pos, uint32* cover
 		prev = hash(pc);
 		if (dedup(sig))
 			continue;
-		write_output(sig);
+		write_output64(sig&COVERAGE_SIG_MASK);
 		nsig++;
 	}
 	// Write out number of signals.
@@ -826,7 +889,7 @@ void handle_completion(thread_t* th)
 		copyout_call_results(th);
 	if (!collide && !th->colliding) {
 		write_call_output(th, true);
-		write_extra_output();
+		write_extra_output(th->monpipe);
 	}
 	th->executing = false;
 	running--;
@@ -905,9 +968,9 @@ void write_call_output(thread_t* th, bool finished)
 		*comps_count_pos = comps_size;
 	} else if (flag_cover) {
 		if (is_kernel_64_bit)
-			write_coverage_signal<uint64>(&th->cov, signal_count_pos, cover_count_pos);
+		        write_coverage_signal<uint64>(&th->cov, signal_count_pos, cover_count_pos, th->monpipe);
 		else
-			write_coverage_signal<uint32>(&th->cov, signal_count_pos, cover_count_pos);
+		        write_coverage_signal<uint32>(&th->cov, signal_count_pos, cover_count_pos, th->monpipe);
 	}
 	debug_verbose("out #%u: index=%u num=%u errno=%d finished=%d blocked=%d sig=%u cover=%u comps=%u\n",
 		      completed, th->call_index, th->call_num, reserrno, finished, blocked,
@@ -933,7 +996,7 @@ void write_call_output(thread_t* th, bool finished)
 #endif
 }
 
-void write_extra_output()
+void write_extra_output(int monpipe)
 {
 #if SYZ_EXECUTOR_USES_SHMEM
 	if (!flag_cover || !flag_extra_cover || flag_collect_comps)
@@ -949,9 +1012,9 @@ void write_extra_output()
 	uint32* cover_count_pos = write_output(0); // filled in later
 	write_output(0); // comps_count_pos
 	if (is_kernel_64_bit)
-		write_coverage_signal<uint64>(&extra_cov, signal_count_pos, cover_count_pos);
+	       write_coverage_signal<uint64>(&extra_cov, signal_count_pos, cover_count_pos, monpipe);
 	else
-		write_coverage_signal<uint32>(&extra_cov, signal_count_pos, cover_count_pos);
+	       write_coverage_signal<uint32>(&extra_cov, signal_count_pos, cover_count_pos, monpipe);
 	cover_reset(&extra_cov);
 	debug_verbose("extra: sig=%u cover=%u\n", *signal_count_pos, *cover_count_pos);
 	completed++;
@@ -1045,6 +1108,8 @@ static uint32 hash(uint32 a)
 
 const uint32 dedup_table_size = 8 << 10;
 uint32 dedup_table[dedup_table_size];
+const uint32 dedup_table_size2 = 8 << 10;
+uint32 dedup_table2[dedup_table_size2];
 
 // Poorman's best-effort hashmap-based deduplication.
 // The hashmap is global which means that we deduplicate across different calls.
@@ -1063,6 +1128,20 @@ static bool dedup(uint32 sig)
 	dedup_table[sig % dedup_table_size] = sig;
 	return false;
 }
+static bool dedup2(uint32 sig)
+{
+	for (uint32 i = 0; i < 4; i++) {
+		uint32 pos = (sig + i) % dedup_table_size2;
+		if (dedup_table2[pos] == sig)
+			return true;
+		if (dedup_table2[pos] == 0) {
+			dedup_table2[pos] = sig;
+			return false;
+		}
+	}
+	dedup_table2[sig % dedup_table_size2] = sig;
+	return false;
+}
 #endif
 
 template <typename T>
@@ -1238,6 +1317,18 @@ uint32* write_output(uint32 v)
 	return output_pos++;
 }
 
+uint32* write_output64(uint64 v)
+{
+	if (output_pos < output_data || (char*)output_pos >= (char*)output_data + kMaxOutput)
+	        fail("output overflow: pos=%p region=[%p:%p]",
+		     output_pos, output_data, (char*)output_data + kMaxOutput);
+	uint64* tmp64 = (uint64*)output_pos;
+	*tmp64 = v;
+	tmp64 ++;
+	output_pos = (uint32*)tmp64;
+	return output_pos;
+}
+
 void write_completed(uint32 completed)
 {
 	__atomic_store_n(output_data, completed, __ATOMIC_RELEASE);
diff --git a/pkg/ipc/ipc.go b/pkg/ipc/ipc.go
index e1e22445..5fc812fa 100644
--- a/pkg/ipc/ipc.go
+++ b/pkg/ipc/ipc.go
@@ -84,7 +84,7 @@ const (
 
 type CallInfo struct {
 	Flags  CallFlags
-	Signal []uint32 // feedback signal, filled if FlagSignal is set
+	Signal []uint64 // feedback signal, filled if FlagSignal is set
 	Cover  []uint32 // per-call coverage, filled if FlagSignal is set and cover == true,
 	// if dedup == false, then cov effectively contains a trace, otherwise duplicates are removed
 	Comps prog.CompMap // per-call comparison operands
@@ -347,10 +347,11 @@ func (env *Env) parseOutput(p *prog.Prog) (*ProgInfo, error) {
 			extraParts = append(extraParts, CallInfo{})
 			inf = &extraParts[len(extraParts)-1]
 		}
-		if inf.Signal, ok = readUint32Array(&out, reply.signalSize); !ok {
+		if inf.Signal, ok = readUint64Array(&out, reply.signalSize); !ok {
 			return nil, fmt.Errorf("call %v/%v/%v: signal overflow: %v/%v",
 				i, reply.index, reply.num, reply.signalSize, len(out))
 		}
+
 		if inf.Cover, ok = readUint32Array(&out, reply.coverSize); !ok {
 			return nil, fmt.Errorf("call %v/%v/%v: cover overflow: %v/%v",
 				i, reply.index, reply.num, reply.coverSize, len(out))
@@ -377,10 +378,10 @@ func convertExtra(extraParts []CallInfo) CallInfo {
 		extraSignal.Merge(signal.FromRaw(part.Signal, 0))
 	}
 	extra.Cover = extraCover.Serialize()
-	extra.Signal = make([]uint32, len(extraSignal))
+	extra.Signal = make([]uint64, len(extraSignal))
 	i := 0
 	for s := range extraSignal {
-		extra.Signal[i] = uint32(s)
+		extra.Signal[i] = uint64(s)
 		i++
 	}
 	return extra
@@ -460,6 +461,20 @@ func readUint32Array(outp *[]byte, size uint32) ([]uint32, bool) {
 	return res, true
 }
 
+/* For reading 64-bit signal */
+func readUint64Array(outp *[]byte, size uint32) ([]uint64, bool) {
+	out := *outp
+	/* 4 = sizeof(uint32)? */
+	if int(size)*8 > len(out) {
+		return nil, false
+	}
+	/* range byte flow to 64-bit array  */
+	arr := ((*[1 << 28]uint64)(unsafe.Pointer(&out[0])))
+	res := arr[:size:size]
+	*outp = out[size*8:]
+	return res, true
+}
+
 type command struct {
 	pid      int
 	config   *Config
diff --git a/pkg/runtest/run.go b/pkg/runtest/run.go
index 67f73665..cbcb8a9d 100644
--- a/pkg/runtest/run.go
+++ b/pkg/runtest/run.go
@@ -552,10 +552,10 @@ func RunTest(req *RunRequest, executor string) {
 		}
 		// Detach Signal and Cover because they point into the output shmem region.
 		for i := range info.Calls {
-			info.Calls[i].Signal = append([]uint32{}, info.Calls[i].Signal...)
+			info.Calls[i].Signal = append([]uint64{}, info.Calls[i].Signal...)
 			info.Calls[i].Cover = append([]uint32{}, info.Calls[i].Cover...)
 		}
-		info.Extra.Signal = append([]uint32{}, info.Extra.Signal...)
+		info.Extra.Signal = append([]uint64{}, info.Extra.Signal...)
 		info.Extra.Cover = append([]uint32{}, info.Extra.Cover...)
 		req.Info = append(req.Info, info)
 	}
diff --git a/pkg/signal/signal.go b/pkg/signal/signal.go
index 20deba46..82132d2b 100644
--- a/pkg/signal/signal.go
+++ b/pkg/signal/signal.go
@@ -9,7 +9,7 @@ import (
 )
 
 type (
-	elemType uint32
+	elemType uint64
 	prioType int8
 )
 
@@ -55,7 +55,7 @@ func (s *Signal) Split(n int) Signal {
 	return c
 }
 
-func FromRaw(raw []uint32, prio uint8) Signal {
+func FromRaw(raw []uint64, prio uint8) Signal {
 	if len(raw) == 0 {
 		return nil
 	}
@@ -114,7 +114,7 @@ func (s Signal) Diff(s1 Signal) Signal {
 	return res
 }
 
-func (s Signal) DiffRaw(raw []uint32, prio uint8) Signal {
+func (s Signal) DiffRaw(raw []uint64, prio uint8) Signal {
 	var res Signal
 	for _, e := range raw {
 		if p, ok := s[elemType(e)]; ok && p >= prioType(prio) {
diff --git a/prog/analysis.go b/prog/analysis.go
index f03f828b..dd4fa865 100644
--- a/prog/analysis.go
+++ b/prog/analysis.go
@@ -182,7 +182,7 @@ const (
 type CallInfo struct {
 	Flags  CallFlags
 	Errno  int
-	Signal []uint32
+	Signal []uint64
 }
 
 const (
@@ -280,7 +280,7 @@ func extractArgSignal(arg Arg, callID, flags int, inf *CallInfo, resources map[*
 	return flags
 }
 
-func DecodeFallbackSignal(s uint32) (callID, errno int) {
+func DecodeFallbackSignal(s uint64) (callID, errno int) {
 	typ, id, aux := decodeFallbackSignal(s)
 	switch typ {
 	case fallbackSignalErrno, fallbackSignalErrnoBlocked:
@@ -292,16 +292,16 @@ func DecodeFallbackSignal(s uint32) (callID, errno int) {
 	}
 }
 
-func encodeFallbackSignal(typ, id, aux int) uint32 {
+func encodeFallbackSignal(typ, id, aux int) uint64 {
 	if typ & ^7 != 0 {
 		panic(fmt.Sprintf("bad fallback signal type %v", typ))
 	}
 	if id & ^fallbackCallMask != 0 {
 		panic(fmt.Sprintf("bad call id in fallback signal %v", id))
 	}
-	return uint32(typ) | uint32(id&fallbackCallMask)<<3 | uint32(aux)<<16
+	return uint64(typ) | uint64(id&fallbackCallMask)<<3 | uint64(aux)<<16
 }
 
-func decodeFallbackSignal(s uint32) (typ, id, aux int) {
+func decodeFallbackSignal(s uint64) (typ, id, aux int) {
 	return int(s & 7), int((s >> 3) & fallbackCallMask), int(s >> 16)
 }
diff --git a/syz-fuzzer/proc.go b/syz-fuzzer/proc.go
index 3b884b2a..ca12a97c 100644
--- a/syz-fuzzer/proc.go
+++ b/syz-fuzzer/proc.go
@@ -265,7 +265,7 @@ func (proc *Proc) execute(execOpts *ipc.ExecOpts, p *prog.Prog, flags ProgTypes,
 
 func (proc *Proc) enqueueCallTriage(p *prog.Prog, flags ProgTypes, callIndex int, info ipc.CallInfo) {
 	// info.Signal points to the output shmem region, detach it before queueing.
-	info.Signal = append([]uint32{}, info.Signal...)
+	info.Signal = append([]uint64{}, info.Signal...)
 	// None of the caller use Cover, so just nil it instead of detaching.
 	// Note: triage input uses executeRaw to get coverage.
 	info.Cover = nil
diff --git a/syz-manager/html.go b/syz-manager/html.go
index bead85a0..b90a5aa6 100644
--- a/syz-manager/html.go
+++ b/syz-manager/html.go
@@ -279,7 +279,7 @@ func (mgr *Manager) httpCoverFallback(w http.ResponseWriter, r *http.Request) {
 	}
 	calls := make(map[int][]int)
 	for s := range maxSignal {
-		id, errno := prog.DecodeFallbackSignal(uint32(s))
+		id, errno := prog.DecodeFallbackSignal(uint64(s))
 		calls[id] = append(calls[id], errno)
 	}
 	data := &UIFallbackCoverData{}
-- 
2.20.1

